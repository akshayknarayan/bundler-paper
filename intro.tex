\section{Introduction}\label{s:intro}
Most Internet paths today employ first-in, first-out (\emph{FIFO}) scheduling. 
However, traffic could benefit from different scheduling algorithms.
The bottleneck link, where congestion occurs and therefore where scheduling is the most useful, is often at the edge of a network, whether an individual device or an autonomous system~\cite{inferring-interdomain-congestion}. 
As a result, deploying scheduling algorithms on one's own routers is of limited utility; often, the congestion occurs in a router outside of one's control.
Unfortunately, networks have proven difficult to evolve; although router vendors have, over the years, implemented other scheduling algorithms (such as fair queueing~\cite{fair-queueing}), operators often do not enable these features.
Thus, the emergence of programmable switching~\cite{p4} is not a panacea; while it might now be simpler to implement scheduling policy, it remains difficult to see deployment.
Meanwhile, in privately operated wide-area networks, operators have used scheduling in the core to reap significant gains~\cite{b4, bwe, swan}. 
Clearly, the use of scheduling policy is beneficial.

Why, then, are operators hesitant to deploy new scheduling policies on congested routers? 
First, scheduling policy can be difficult to configure, and poor configurations can cause significant performance degradation~\cite{nanog-discussion}.
Second, the position of operators in the public Internet is a challenging one, as each of their various customers may desire diverging (often incompatible) features. For example, due to the prevalence of VPN tunnelling, enabling fair queueing in routers may penalize flows bundled within a VPN tunnel.
Thus, operators cannot see the full picture, and cannot offer scheduling that will appease any one customer.

Crucially, however, \emph{individual customers} can often choose a policy that suits their needs; that is, scheduling policy is easier to express at the edge. 
Examples include: traffic between different datacenters over the public Internet; traffic between campuses of an organization; traffic between collaborating universities or companies; traffic between a large content provider (\eg Netflix) and a network with many clients (e.g., a regional ISP); large-scale data backups from an organization to an external site (\eg Dropbox); etc. 
In each of these scenarios the sender has enough information to unilaterally choose a scheduling policy for its component connections, but usually lacks the control over the bottleneck link necessary to realize it.

While it may be easier to \emph{express} scheduling policy near the edge, it is not immediately obvious how to \emph{implement} it. 
Traffic from a domain is naturally comprised of numerous individual connections;
each connection independently probes for bandwidth, detects congestion on its path, and reacts accordingly.

We address this challenge in two steps. 
First, we treat the traffic from multiple component connections as a \emph{single aggregate}, \ie as a router would view them. We decide an combined sending rate for the aggregate. Then, inside the aggregate, we enforce a scheduling policy among the component flows. 
In other words, we decouple the aggregate rate decision from the scheduling policy.
This approach, which we call {\em aggregate traffic control}, therefore has two technical challenges:
\begin{enumerate}
    \item {\bf Congestion control.} At what combined rate should the traffic aggregate send packets? This depends on network conditions at the bottleneck, which the traffic aggregate cannot directly observe.
    Fortunately, this is exactly the question answered by congestion control algorithms; they take as input measurements of network conditions -- RTT, sending rate, receiving rate, etc -- and yield as output a rate at which to send packets.
    Furthermore, since the traffic aggregate as a whole determines the sending rate, this approach causes component flows share congestion information.
    Thus new flows can discover and adapt to their path's congestion conditions much more quickly, which is particularly beneficial for short flows~\cite{CM}. 
    
    \item {\bf Flow scheduling.} Given a combined rate, in what order should the aggregate transmit packets?  This enables fine-grained scheduling for flows within a traffic aggregate. 
    For example, we can schedule flows based on size (short flows first), application priorities, deadlines, etc.
\end{enumerate}

How should we implement and deploy our approach? 
We note that middleboxes are now prevalent in the Internet architecture~\cite{aplomb}.
The rise of middleboxes allows a new vantage point into flows, since middleboxes are often deployed at natural ``choke points'' in a network to ensure traffic transits them for \eg traffic analysis or intrusion detection.
Middleboxes offer a flexible design point, since implementations spanning hardware and software represent numerous options in implementing scalable, yet flexible and sophisticated scheduling policies.
We therefore propose a new type of middlebox to perform traffic aggregation, which we call a \name.

We make the following contributions:
\begin{enumerate}
    \item The design and implementation of a \name, including a novel method of collecting congestion control information and enforcing the decisions of a congestion control algorithm on traffic aggregates. This method \emph{moves} the queues in the network from the bottleneck to the edge.
    \item An evaluation of the benefits of scheduling for traffic aggregates, compared to both the status quo (FIFO) and an idealized deployment where bottleneck queues deploy a scheduling algorithm.
\end{enumerate}

The rest of this paper is organized as follows: 
\S\ref{s:design} describes tradeoffs in the design of a \name. 
\S\ref{s:measurement} describes our approach to gathering measurements from the network. 
\S\ref{s:impl} describes our prototype implementation. 
\S\ref{s:eval} shows an evaluation of the benefits of \name.

\cut{
\begin{outline}
\1 Previously, this approach has required terminating the TCP connection at the middlebox; \ie implementing a TCP proxy.
    \2 TCP proxies are widely used to add congestion control functionality in the network.
    \2 \an{drawbacks of TCP proxies}
        \3 head of line blocking
        \3 implementation complexity
        \3 end-to-end principle
\end{outline}
}
