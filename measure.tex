\section{Measuring Congestion}\label{s:measurement}

% In this section we describe how the \inbox and \outbox coordinate to compute accurate and robust
% measurements of the network conditions necessary as inputs to congestion control algorithms.

% Congestion control algorithms need only a small, common set of measurements~\cite{ccp}. 
% In particular, rate-based algorithms need only three measurements: 
% the sending rate, receiving rate, and path round-trip time.
% A significant complication is that for accurate measurements on RTT time-scales, we must calculate send and receive rates over the same set of packets~\cite{packettrain} \radhika{one line explanation on why}.
% This requirement drives the design of our measurement methodology.

As discussed in the previous section, \name measures network congestion signals (RTT and packet arrival rates) over the duration (or \emph{epochs}) between infrequently sampled packets (that we call \emph{epoch boundary packets}). In this section, we describe our strategy for independently sampling the same set of epoch boundary packets at the paired \name boxes, and for measuring congestion signals using them. We end with an evaluation showing the accuracy of our approach.

\subsection{Determining Epoch Boundaries}
\label{s:measure:marking}

%We now detail our technique for determining the epoch boundary packets at the \inbox and the \outbox, under the assumption that packets leave the \inbox and arrive at the \outbox in the same order.\footnote{We address re-ordering later in Section~\ref{s:measure:limitation:reorder}.} 

Suppose the desired epoch size, i.e. the number of packets between two epoch boundary packets, is $N$. A naive strategy for determining common epoch boundaries at the \inbox and the \outbox, without making any changes to the packet headers, would be to simply sample a packet after every $N$ packets. However, any packet loss in the network would then desynchronize the sampling at the two boxes.\footnote{This can be avoided if the \outbox detects and accounts for packet losses, but that would require maintaining expensive per-flow state, which would break our design's simplicity and scalability.} Another alternative is for the \inbox to explicitly send out-of-band messages to the \outbox indicating which packets are to be sampled. However, there is no guarantee that these messages would arrive at and be processed by the \outbox before the indicated packets arrive themselves. 
%, i.e. it is required that an epoch boundary packet be sampled after every $N$ packets at the \inbox and the \outbox.
% Consider the stream of packets $P_B$ from all flows in a bundle $B$ in the order they leave the \inbox after scheduling.
% The \inbox and \outbox need to know how to divide this stream into sets 
% of packets --- which we call \emph{epochs} --- over which they can calculate measurements.
% For now, we make the simplifying assumption that packets arrive at the \outbox in the same order they 
% left the \inbox.
% This simplifies the problem into deciding, for all given packets in $P_B$, whether it is an epoch boundary packet at which the current epoch should end and the next should begin. 
% Suppose for now that we wish to have a fixed epoch size of $N$ packets.
% A naive approach would be to mark the boundary between epochs every $N$ packets. 
% However, this strategy is brittle; a single lost packet would de-synchronize the boxes' views of the epochs. 
% More generally, any strategy that requires packet-level synchronization of the \inbox and
% \outbox is untenable because any coordination would race the packets themselves \radhika{i don't quite understand the last sentence}.

Our technique side-steps these issues by using the contents of a packet to sample epoch boundaries. More specifically, a packet is sampled as a boundary for an epoch of size $N$, if the hash over a subset of its fields is a multiple of $N$. Therefore, given sufficient entropy in the hashed values, an epoch boundary will, in expectation, be sampled once every $N$ packets.

% The key idea of our methodology is that we can avoid such a synchronization problem by determining the boundary of an epoch using only information contained in the packet.
% Specifically, we propose the following: a packet $p$ is an epoch boundary packet if the hash 
% of some subset of its header (see below) modulo the epoch size $N$ is equal to 0, that is:
% Specifically, we propose the following: a packet $p$ is an epoch boundary packet if the hash 
% of some subset of its header (see below) modulo the epoch size $N$ is equal to 0, that is:
% \begin{algorithm}
% def is_boundary_packet(pkt, N): # N is sample size \\
%     return ( H(pkt.header) \% N ) == 0
% \end{algorithm}
% \radhika{equation not super clear}
% Thus, an epoch boundary packet will occur (in expectation) once every $N$ packets.
% For $H$, we use the Fowler/Noll/Vo (FNV) hash function~\cite{fnv-hash}, a non-cryptographic fast hash function with a low collision rate. 


%\paragrapha{Choosing header subset} 
The combination of selected packet fields, over which the hash is computed, can vary across different deployments. However, it must satisfy the following requirements: 

\paragraphn{(i)} It must be the same at both the \inbox and the \outbox.

\paragraphn{(ii)} Its values must remain unchanged as a packet traverses the network from the \inbox to the \outbox (so, for example, the TTL field must be excluded).\footnote{Certain fields, that are otherwise unchanged within the network, can be changed by the NATs deployed in a customer's domain. Ensuring that the \name boxes sit outside the NAT would allow them to make use of those fields.} 

\paragraphn{(iii)} It differentiates individual \emph{packets} (and not just flows), to allow sufficient entropy in the computed hash values.
%, which is required for achieving the desired epoch size.  

\paragraphn{(iv)} It also differentiates a retransmitted packet from the original one, to prevent spurious samples from disrupting the measurements (so, for example, just using TCP sequence numbers combined with a flow's five tuple is insufficient).

The combination of IP ID, source port and source IP (used by our prototype implementation in \ref{s:impl}) is one possible option that satisfies all of the above requirements.  

%, to ensure that the same set of packets is sampled at the two boxes. 
%This rules out hashing the entire packet, since its TTL field would change with every hop. Using TCP sequence numbers, combined with the five-tuple flow identifier is tempting. the resulting inability to distinguish TCP retransmissions from original packets would cause spurious sampling, which would throw off the RTT measurements.


% The header subset we use must remain constant as the packet traverses the network from the \inbox to the \outbox; otherwise, they would not be able to agree on epoch boundaries. This rules out simple approaches such as hashing the entire packet header, since the TTL field will decrement between the inbox and outbox.
% Even the 5-tuple of the packet may change, since the outbox may be behind a NAT.
% Using TCP sequence numbers is tempting, but retransmissions may confuse RTT measurements.

% We use the IP ID field, which will change every packet. This is an imperfect solution, as modern NATs may rewrite the IP ID field~\cite{ipid}.
% Ultimately, the appropriate field to use will depend on the specific deployment of \name. \fc{come back to this, mention boxes are not likely to be behind NATs therefore you can do ipid+5tuple }

\subsection{Computing Measurements}
\label{s:measure:compute}
\newcommand{\pone}{$p_{i-1}$}
\newcommand{\hpone}{$h(p_{i-1})$}
\newcommand{\sone}{$s_{i-1}$}
\newcommand{\rone}{$r_{i-1}$}
\newcommand{\ptwo}{$p_{i}$}
\newcommand{\hptwo}{$h(p_{i})$}
\newcommand{\stwo}{$s_{i}$}
\newcommand{\rtwo}{$r_{i}$}
\newcommand{\atwo}{$a_{i}$}
\newcommand{\sentone}{$sent_{i-1}$}
\newcommand{\recvdone}{$rcvd_{i-1}$}
\newcommand{\senttwo}{$sent_{i}$}
\newcommand{\recvdtwo}{$rcvd_{i}$}


\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{img/rate-calculation}
    \caption{Example of epoch-based measurement calculation. Time moves from top to bottom.
    %Packets from flows in a bundle
    %pass through the \inbox and \outbox middleboxes on the way to their destination. 
    The \inbox records the packets that are identified as epoch boundaries. 
    The \outbox, up on identifying such packets, sends a feedback message back to
    the \inbox, which allows it to calculate the RTT and epochs.
    %When the \inbox observes a packet header matching the boundary condition, it records it. 
    %When the \outbox observes this packet, it sends an out-of-band feedback message back to
    %the \inbox, which allows it to calculate the RTT and epochs.
    }\label{fig:ratecalc}
\end{figure}

Given our technique to identify epoch boundaries, it is straight-forward to measure congestion signals, as illustrated in Figure~\ref{fig:ratecalc}.
%Given this method of marking epochs, we can now construct the procedure for computing measurements.
For each bundle, the \inbox tracks the total number of bytes sent since the last epoch boundary, and, upon identifying an epoch boundary packet, $p_i$, it records: (i) its hash, $h(p_i)$, (ii) the time when it is sent out, $t_{\text{sent}}(p_i)$, and (iii) the number of bytes sent since the last epoch boundary, $b_{sent}(p_i)$. 
The \outbox, on the other hand, tracks only the total number of bytes received since the last epoch boundary. Upon the arrival and identification of the same epoch boundary packet, $p_i$, it immediately sends a feedback message to the \inbox containing: (i) its hash, $h(p_i)$, (ii) the time when it was received, $t_{recv}(p_i)$, and (iii) the number of bytes received since the last epoch boundary, $b_{recv}(p_i)$. 
%For each bundle, the \inbox keeps track of: (i) the total number of bytes sent since the last epoch, (ii)  
% For a given bundle, the \inbox runs the aforementioned function on each packet $p$. Each time
% the function returns true, the \inbox updates an epoch data structure that records the packet hash,
% which we will call \hptwo\ for the current epoch, 
% along with the current time \stwo\ and the \emph{cumulative} number of bytes sent so far, \senttwo. This structure
% is sorted by the time the packet was sent, \stwo, but is indexable by the packet hash.
% The \outbox runs the same function. Each time it observes a boundary packet, 
% it immediately sends a feedback message to the \inbox containing the same information:
% the packet hash \hptwo, the time at which it received the packet, \rtwo, and the cumulative number of bytes
% \emph{received} up until that point. 
% When the \inbox receives this feedback message at time \atwo, it looks up the
% packet hash \hptwo\ in the epoch data structure, which represents the end of the current epoch,
% along with the earliest boundary packet still in the data structure, \hpone\ which represents the start
% of the current epoch. It now has all of the information necessary to calculate one sample of the following:
Upon receiving the feedback $p_i$, the \inbox uses its recorded state to compute the RTT and the rates at which packets are sent and received as below:

% \begin{subequations}
%     \begin{align}
%         RTT &= &now - s_2 \\
%         \cut{
%         send\_epoch\_duration &= &s_2 - s_1\\
%         recv\_epoch\_duration &= &r_2 - r_1\\
%         bytes\_sent\_in\_epoch &= &bytes\_sent\ at\ s_2 &\ - \\
%                                     &&bytes\_sent\ at\ s_1&\notag\\
%         bytes\_rcvd\_in\_epoch &= &bytes\_rcvd\ at\ r_2 &\ - \\
%                                 &&bytes\_rcvd\ at\ r_1\notag\\
%         send\_rate &= &\frac{bytes\_sent\_in\_epoch}{send\_epoch\_duration}\\
%         recv\_rate &= &\frac{bytes\_rcvd\_in\_epoch}{recv\_epoch\_duration}
%         }
%         send\_rate &= &\frac{bytes\_sent\ at\ s_2 - bytes\_sent\ at\ s_1}{s_2-s_1}\\
%         recv\_rate &= &\frac{bytes\_rcvd\ at\ r_2 - bytes\_rcvd\ at\ r_1}{r_2-r_1}
%     \end{align}
% \end{subequations}

\begin{subequations}
    \begin{align}
        RTT &= &now -  t_{sent}(p_i)\\
        send\_rate &= &\frac{b_{sent}(p_i) - b_{sent}(p_{i-1})}{t_{sent}(p_i)-t_{sent}(p_{i-1})}\\
        recv\_rate &= &\frac{b_{recv}(p_i) - b_{recv}(p_{i-1})}{t_{recv}(p_i)-t_{recv}(p_{i-1})}
    \end{align}
\end{subequations}

Finally, the \inbox records the information received in the feedback for $p_i$, and clears the recorded state of all epoch boundaries preceding $p_i$.


Note that our measurement technique, as described above, is robust to a boundary packet being lost between the \inbox and the \outbox. In this case, the \inbox would not get a feedback for the lost boundary packet, and it would simply compute rates for the next boundary packet over a longer epoch. 

%Further note, that our discussion so far has ignored re-ordering of packets between the \inbox and \outbox, in which case, they can see different number of packets between each epoch boundary, which can interfere with the rate computations. We expect such re-ordering to be rare, although computing   


%(Note $bytes\_rcvd\_in\_epoch$ can also be interpreted as the number of bytes
%acknowledged for that epoch, which is a common signal used by many conestion
%control algorithms.)
%\radhika{fix brackets!}
%leaving \ptwo\ to be the start of the next epoch.


% \paragrapha{Crashes \an{need better heading}} Existing work~\cite{ftmb} has studied how to design stateful middleboxes to be fault-tolerant with acceptable performance overheads. 
% However, state-persistence is largely unnecessary for \name.
% \name only stores network conditions, which it can re-learn within a few RTTs, and bundle membership flow tables, which it can re-discover as we describe in~\S\ref{s:impl:discovery}. 
% \radhika{maybe move elsewhere}

\subsection{Choosing The Epoch Size}
\label{s:measure:epoch}
%\input{micro-epoch}

% How do we choose the number of packets that should e in each epoch?
In \S\ref{s:measure:marking}, we assumed a fixed epoch size of $N$ packets. However, in practice, epochs must be such that measurements are collected at least once per RTT~\cite{ccp}. Therefore, for each bundle, we track that minimum observed RTT ($minRTT$ at the \inbox and set the epoch size $N = (0.25 \times minRTT \times send\_rate)$, where the $send\_rate$ is computed as described above. The final rates passed to the congestion control algorithms at the \inbox are then computed over a sliding window of epochs that corresponds to one RTT.\footnote{Averaging over a window of multiple epochs also increases resilience to possible (though rare) re-ordering of packets between the \inbox and the \outbox, which can result in them seeing different number of packets between two epochs.} 
%This makes epoch size a function of the bandwidth-delay product (BDP).
% Because epoch sizes are sampled from a uniform random variable, setting larger epoch sizes will increase the variance in the observed epoch sizes.
% If the epoch size is small relative to the rate, the raw measurements will be noisy, but we can correct for this by measuring over a sliding window.

% How do we choose the number of packets that should e in each epoch?
% In \S\ref{s:measure:marking}, we assumed a fixed epoch size of $N$ packets.
% However, in practice, the epoch must be a function of the bandwidth-delay product (BDP).
% Because epoch sizes are sampled from a uniform random variable, setting larger epoch sizes will increase the variance in the observed epoch sizes.
% If the epoch size is small relative to the rate, the raw measurements will be noisy, but we can correct for this by measuring over a sliding window.

% Therefore, we estimate the BDP (current sending rate multiplied by current estimate of the RTT) and set the desired epoch size to one-fourth of this value. We then calculate rates over a sliding window of four epochs; this is approximately one RTT.


When the \inbox updates the epoch size $N$ for a bundle, it needs to send an out-of-band message to the \outbox communicating the new value. To keep our measurement technique resilient to potential delay and loss of this message, the epoch size $N$ is always rounded down to the nearest power of two. Doing this ensures that the epoch boundary packets sampled by the \outbox are either a strict superset or a strict subset of those sampled by the \inbox. The \inbox simply ignores the additional feedback messages in former case, and the recorded epoch boundaries for which no feedback has arrived in the latter.  

%As the sending rate and RTT change, the \inbox will update the desired epoch size accordingly, and communicate this desired epoch size to the \outbox.
% This communication might be lost. 
% Therefore, when setting the desired epoch size we round down to the nearest power of two so that the \outbox's view of the epoch boundary packets is a sub- or super- set of the \inbox's:
% for example, 
% if the \inbox's desired epoch size is $64$ packets
% but the \outbox does not receive this update and still believes the desired epoch size is $128$ packets, 
% the \outbox's feedback will still match (in expectation) half the \inbox's epoch boundary packets.


% \subsection{Dealing with packet re-ordering and losses}

% \Para{Packet Loss} Our technique is robust to loss of boundary packets between the \inbox and the \outbox.
% Suppose the \inbox sees boundary packets $p_1, p_2, p_3$, but $p_2$ is lost after passing through
% the \inbox so the \inbox only receives feedback for $p_1$ and $p_3$. Upon receiving $p_1$, 
% the \inbox will truncate its data structure up until $p_1$. Upon receiving $p_3$, the \inbox 
% looks up the oldest remaining boundary packet, $p_1$, and considers that the beginning of the epoch.
% As a result, the epoch is longer than expected, but no measurements are lost or corrupted. 
% The same argument applies to the loss of feedback messages. 
% Importantly, \inbox calculates both the send and receive epoch based on information
% from the \outbox rather than attempting to reach consensus on individual epoch boundaries with the \outbox.

% \Para{Packet loss} This method is robust to the loss of boundary packets between the \inbox and \outbox.
% Suppose the \inbox sees boundary packets $p_1, p_2, p_3$, but $p_2$ is lost after passing through
% the \inbox so the \inbox only receives feedback for $p_1$ and $p_3$. Upon receiving $p_1$, 
% the \inbox will truncate its data structure up until $p_1$. Upon receiving $p_3$, the \inbox 
% looks up the oldest remaining boundary packet, $p_1$, and considers that the beginning of the epoch.
% As a result, the epoch is longer than expected, but no measurements are lost or corrupted. 
% The same argument applies to the loss of feedback messages. 
% Importantly, \inbox calculates both the send and receive epoch based on information
% from the \outbox rather than attempting to reach consensus on individual epoch boundaries with the \outbox. 

%\Para{Re-Ordering}
%\label{s:measure:limitation:reorder}

% Earlier we ignored re-ordering of packets between the \inbox and \outbox. However, if packets
% are re-ordered, the \inbox and \outbox will observe a different view of the same epoch.
% For example, consider packets numbered 1 to 20, where 10 is a boundary packet. The \inbox observes
% 10 packets in each epoch: [1,10] in epoch 1 and [11,20] in epoch 2. 
% However, suppose packet 7 is delayed and arrives after packet 10. The \outbox will observe 9
% packets in epoch 1 and 11 packets in epoch 2. 
% Spurious re-ordering can be compensated by using an EWMA across epochs rather than the raw values
% calculated at each epoch. If there is persitent re-ordering, it may be necessary to add a constant 
% value to either the send or receive rate to compensate.
%\radhika{the explanation seems a bit hand-wavy. if we end up doing ecmp expt and the results look good, add fwd pointer to those results}



% \subsubsection{Suitable Algorithms}
% \label{s:measure:limitation:algs}
% The set of measurements we obtain are sufficient for most rate-based algorithms, but may not be 
% suitable for traditional window-based algorithms which require low-level metrics such as 
% the number of inflight packets or number of packets lost. Although it should be possible
% to compute these from the measurements we already collect in an ideal scenario, they would easily
% break in the presence of network anomilies such as re-ordering. Thus, we leave the development
% of robust signals for window-based algorithms to fuure work. 
% Thus, \name currently operates best with rate-based algorithms such as BBR, Nimbus, or Copa~\cite{bbr,nimbus,copa}.
% \radhika{feels like this should be moved to Sec 3, but am  not entirely sure.}
% \radhika{discuss}

\subsection{Microbenchmarks}
\label{s:measure:microbench}
    \input{micro-time}
    \input{micro-thru-dist}
    \input{micro-delay-dist}
    We now explore how well our measurements match the actual network conditions. 

    %First, we consider our estimate of the receive rate (Equation 1c). 
    In Figure~\ref{fig:micro:time}, we compare our estimate of the receive rate (``Measured'')
    to the actual rate of packets 
    leaving the bottleneck over a five second segment from one run in our evaluation (\fc{expand}).
    Here we demonstrate the necessity of a window to smooth out the estimation.

    In Figure~\ref{fig:micro:thru}, we compute the difference between our smoothed estimate of the receive rate 
    and the bottleneck rate at each time step and plot the distribution of this difference across
    all of the traces in our evaluation. 80\% of the time our estimate is within 3Mbps of the 
    actual rate.

    In Figure~\ref{fig:micro:delay}, we compute the difference between our estimate of the RTT between
    the \inbox and \outbox and the actual RTT at each time stpe and plot the distribution again
    across all of the traces in our evaluation. 80\% of the time we are within 2ms of the actual RTT.
    \radhika{discuss}
    
